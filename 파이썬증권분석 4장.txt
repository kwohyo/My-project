[p.188]--작동 안됨
from bs4 import BeautifulSoup
from urllib.request import urlopen
url='https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'
with urlopen(url) as doc:
html=BeautifulSoup(doc,'lxml') 
pgrr=html.find('td',class_='pgRR')
print(pgrr.a['href']) 
print(pgrr.prettify())

[p.188]--깃허브
from bs4 import BeautifulSoup
import requests
url = 'https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'
html = BeautifulSoup(requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text, "lxml")
pgrr = html.find('td', class_='pgRR') 
print(pgrr.a['href'])

print(pgrr.prettify())
print(pgrr.text)

[p.189]
with urlopen(url) as doc:
html = BeautifulSoup(requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text, "lxml")
pgrr=html.find('td',class_='pgRR')
s=str(pgrr.a['href']).split('=')
last_page=s[-1]

[p.190]
import pandas as pd
df=pd.DataFrame()
sise_url='https://finance.naver.com/item/sise_day.nhn?code=068270'
for page in range(1, int(last_page)+1):
page_url='{}&page={}'.format(sise_url,page)
df = pd.concat([df, pd.read_html(html, header=0)[0]])
df=df.dropna()

[p.193]--중간에 오류 발생 그래프는 뜨는데 데이터가 없음
import pandas as pd
from urllib.request import urlopen
from bs4 import BeautifulSoup
from matplotlib import pyplot as plt

url='https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'
with urlopen(url) as doc:
	html = BeautifulSoup(requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text, "lxml")
	pgrr=html.find('td',class_='pgRR')
	s=str(pgrr.a['href'].split('=')
	last_page=s[-1]

df=pd.DataFrame()
sise_url='https://finance.naver.com/item/sise_day.nhn?code=068270'
for page in range(1,int(last_page)+1):
	page_url='{}&page={}'.format(sise_url,page)
	df = pd.concat([df, pd.read_html(html, header=0)[0]])

df=df.dropna()
df=df.iloc[0:30]
df=df.sort_values(by='날짜')

plt.title('Celltrion(close)')
plt.xticks(rotation=45)
plt.plot(df['날짜'],df['종가'],'co-')
plt.grid(color='gray',linestyle='--')
plt.show()

[4.4.4 전체 페이지 읽어오기]-p.190

from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://finance.naver.com/item/sise_day.nhn?code=068270&page=1'
html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text
bs = BeautifulSoup(html, 'lxml')
pgrr = bs.find('td', class_='pgRR')
print(pgrr.a['href'])

s = str(pgrr.a['href']).split('=')
last_page = s[-1]

df = pd.DataFrame()
sise_url = 'https://finance.naver.com/item/sise_day.nhn?code=068270'

for page in range(1, int(last_page)+1):
    page_url = '{}&page={}'.format(sise_url, page)
    page_txt = requests.get(page_url, headers={'User-agent': 'Mozilla/5.0'}).text
    df = df.append(pd.read_html(page_txt, header=0)[0])

df = df.dropna()
print(df)
